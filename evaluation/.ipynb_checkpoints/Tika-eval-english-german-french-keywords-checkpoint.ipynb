{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(file):\n",
    "    execute = [\"java\", \"-jar\", \"../jars/tika-app-1.24.1.jar\", \"-l\", file]\n",
    "    return subprocess.run(execute, capture_output=True).stdout.decode()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"../data/qald-3-test.csv\",\"../data/qald-4-test.csv\",\"../data/qald-5-test.csv\",\"../data/qald-6-test.csv\",\"../data/qald-7-test.csv\",\"../data/qald-8-test.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "times=[]\n",
    "for d in l:\n",
    "    df_test = pd.read_csv(d)\n",
    "    df_test=df_test.dropna(subset=['questions'])\n",
    "    df_test = df_test[df_test[\"lang\"]==\"en\"]\n",
    "    total_time = datetime.datetime.now()\n",
    "    temp=total_time\n",
    "    total_time-=temp\n",
    "    out=[]\n",
    "    for text in df_test['questions']:\n",
    "        with open('../X.txt', 'w') as f:\n",
    "            f.write(text)\n",
    "        if f.closed:\n",
    "            a = datetime.datetime.now()\n",
    "            out.append(detect('../X.txt'))\n",
    "            b= datetime.datetime.now()\n",
    "        c = b-a\n",
    "        total_time+=c\n",
    "    \n",
    "    scores.append(accuracy_score(df_test['lang'],out))\n",
    "    times.append(total_time/len(df_test['lang']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(\"../data/qald-3-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test=df_test.dropna(subset=['questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect(file):\n",
    "#     execute = [\"java\", \"-jar\", \"../jars/tika-app-1.24.1.jar\", \"-l\", file]\n",
    "#     return subprocess.run(execute, capture_output=True).stdout.decode()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_time = datetime.datetime.now()\n",
    "# temp=total_time\n",
    "# total_time-=temp\n",
    "# out=[]\n",
    "# for text in df_test['questions']:\n",
    "#     with open('../X.txt', 'w') as f:\n",
    "#         f.write(text)\n",
    "#     if f.closed:\n",
    "#         a = datetime.datetime.now()\n",
    "#         out.append(detect('../X.txt'))\n",
    "#         b= datetime.datetime.now()\n",
    "#     c = b-a\n",
    "#     total_time+=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3 0.8838\n",
    "# q4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(df_test['lang'],out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_time/len(df_test['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9595959595959596,\n",
       " 0.96,\n",
       " 0.9491525423728814,\n",
       " 0.96,\n",
       " 0.8837209302325582,\n",
       " 0.975609756097561]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(seconds=1, microseconds=523762),\n",
       " datetime.timedelta(seconds=1, microseconds=653303),\n",
       " datetime.timedelta(seconds=1, microseconds=635263),\n",
       " datetime.timedelta(seconds=1, microseconds=642308),\n",
       " datetime.timedelta(seconds=1, microseconds=614192),\n",
       " datetime.timedelta(seconds=1, microseconds=605435)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"../data/qald-3-test.csv\",\"../data/qald-4-test.csv\",\"../data/qald-5-test.csv\",\"../data/qald-6-test.csv\",\"../data/qald-7-test.csv\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "times=[]\n",
    "for d in l:\n",
    "    df_test = pd.read_csv(d)\n",
    "    df_test=df_test.dropna(subset=['questions'])\n",
    "    df_test = df_test[df_test[\"lang\"]==\"de\"]\n",
    "    total_time = datetime.datetime.now()\n",
    "    temp=total_time\n",
    "    total_time-=temp\n",
    "    out=[]\n",
    "    for text in df_test['questions']:\n",
    "        with open('../X.txt', 'w') as f:\n",
    "            f.write(text)\n",
    "        if f.closed:\n",
    "            a = datetime.datetime.now()\n",
    "            out.append(detect('../X.txt'))\n",
    "            b= datetime.datetime.now()\n",
    "        c = b-a\n",
    "        total_time+=c\n",
    "    \n",
    "    scores.append(accuracy_score(df_test['lang'],out))\n",
    "    times.append(total_time/len(df_test['lang']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9494949494949495, 0.92, 0.9387755102040817, 0.88, 0.9534883720930233]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(seconds=1, microseconds=445953),\n",
       " datetime.timedelta(seconds=1, microseconds=422195),\n",
       " datetime.timedelta(seconds=1, microseconds=396230),\n",
       " datetime.timedelta(seconds=1, microseconds=406229),\n",
       " datetime.timedelta(seconds=1, microseconds=410976)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "times=[]\n",
    "for d in l:\n",
    "    df_test = pd.read_csv(d)\n",
    "    df_test=df_test.dropna(subset=['questions'])\n",
    "    df_test = df_test[df_test[\"lang\"]==\"fr\"]\n",
    "    total_time = datetime.datetime.now()\n",
    "    temp=total_time\n",
    "    total_time-=temp\n",
    "    out=[]\n",
    "    for text in df_test['questions']:\n",
    "        with open('../X.txt', 'w') as f:\n",
    "            f.write(text)\n",
    "        if f.closed:\n",
    "            a = datetime.datetime.now()\n",
    "            out.append(detect('../X.txt'))\n",
    "            b= datetime.datetime.now()\n",
    "        c = b-a\n",
    "        total_time+=c\n",
    "    \n",
    "    scores.append(accuracy_score(df_test['lang'],out))\n",
    "    times.append(total_time/len(df_test['lang']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8888888888888888, 0.98, 0.9333333333333333, 0.93, 1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(seconds=1, microseconds=643821),\n",
       " datetime.timedelta(seconds=1, microseconds=644057),\n",
       " datetime.timedelta(seconds=1, microseconds=636548),\n",
       " datetime.timedelta(seconds=1, microseconds=645568),\n",
       " datetime.timedelta(seconds=1, microseconds=659754)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
